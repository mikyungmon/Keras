# Chapter 02 # 

**인공신경망(Artificial Neural Network)** 이란? 

  - **생체의 신경망을 흉내 낸 인공지능이다.**

  - 입력, 은닉, 출력 계층으로 구성되어 있으며 은닉 계층을 한 개 이상 포함할 수 있다.

  - 초기에는 기술적인 한계로 은닉 계층을 한 개만 포함하여 전체 3개의 계층으로 ANN을 구성했다. 

  - 넓은 의미로 인공 신경망을 총칭하는 용어로 ANN을 사용하기도해서 단일 은닉 계층의 ANN을 얉은 신경망으로 구분해서 부르기도 한다.
   
   
## 2.1 ANN의 원리 ## 

### 2.1.1 ANN의 개념 ### 

ANN은 생체 신경망 구조와 유사하게 은닉 계층을 포함하는 인공신경망 기술이다. 

초기에는 은닉 계층이 하나였다. 은닉 계층이 둘 이상이면 가중치 최적화가 어려워 신경망의 성능을 보장할 수 없었기 때문이다.

과거에 가중치 최적화에 대한 연구가 활발하지 못했던 이유로는 충분하지 못한 데이터양도 있다. 빅데이터 시대 이전에는 데이터 양이 많지 않았기 때문이다.

그리고 스몰데이터에는 신경망 대신할 다신 머신러닝 방법이 존재했다. 예를 들어 SVM은 데이터가 적을 때 아주 우수한 성능을 보인다.

그렇지만 처리할 데이터양이 늘어나거나 비정형 데이터인 경우는 복잡도가 높아서 활용하기가 쉽지 않다 => 이런 경우 **ANN이 더 효과적이다.**

### 2.1.2 ANN 구조 ### 

은닉 계층이 하나인 ANN으로 기본 구조를 살펴보자.

ANN은 **입력계층, 은닉계층, 출력계층**으로 구성되고 각 계층은 순서별로 여러 입력노드, 은닉노드, 출력노드를 포함한다.

< 동작 순서 >

1. 입력 계층을 통해 외부로부터 들어온 입력 신호 벡터(x)에 ㅈ가중치 행렬 W_xh를 곱하여 은닉 계층으로 보낸다.

2. 은닉 계층의 각 노드들은 자신에게 입력된 신호 벡터에 **활성화 함수**인 f_n()를 적용한 결과 벡터(h)로 내보낸다. 활성화 함수에는 시그모이드, 하이퍼볼릭탄센트 함수 등이 있다.

3. 은닉 계층의 결과 벡터에 새로운 가중치 행렬 W_hy를 곱한 뒤 출력 계층으로 보낸다.

4. 출력 계층으로 들어온 신호 벡터에 출력 활성화 함수인 f_y()를 적용하고 그 결과 벡터(y)를 신경망 외부로 최종 출력한다. 분류의 경우에는 출력용 활성화 함수로 **소프트맥스** 연산을 주로 사용한다.

![image](https://user-images.githubusercontent.com/66320010/119773060-10a13080-befb-11eb-9f3f-d0251d8f2a89.png)

### 2.1.3 ANN 활용 ### 

ANN의 기본적인 활용 방법은 **분류**와 **회귀**로 나눌 수 있다. 

  - 분류 ANN : 입력 정보를 클래스 별로 분류하는 방식 -> ex) 필기체 숫자를 0부터 9로 분류하기
  - 회귀 ANN : 입력 정보로 다른 값을 예측하는 방식 -> ex) 최근 일주일간 평균 온도로 내일 평균 온도 예측하기

#### [ 분류 ANN ] ####

분류 ANN이란?

- 입력 정보를 바탕으로 해당 입력이 어느 클래스에 속하는지를 결정하는 것

- 예를 들어 필기체 숫자가 적힌 그림을 보고 어느 숫자인지 분류하는 경우

- 입력 계층은 필기체 숫자를 받아들이고 출력 계층은 분류한 결과를 출력한다.

- 분류 결과를 출력하는 방법으로 노드 하나를 사용해 분류 결과를 수로 표현하는 방법이 있다. 그러나 분류 ANN은 숫자로 출력하는 방법보다 분류할 클래스 수만큼 출력 노드를 만드는 방법이 효과적이라고 알려져 있다.

- 따라서 만약 0과 1 두 숫자에 해당하는 필기체 그림을 분류하는 경우에는 출력 노드를 두 개 만드는 것이 효과적이다.

- 판별은 두 출력 노드의 값을 비교하여 더 큰 쪽을 선택하도록 구현한다.

**이와 같이 ANN을 이용하여 예측값을 추론하는 과정을 전방향 예측이라고 한다. 반면 ANN을 구성하는 가중치의 학습은 예측값의 목표값에 대한 오차를 역방향으로 되돌리면서 이루어지기 때문에 오차역전파라고 한다.**

오차 역전파 : 오차를 줄이는 경사 하강법(gradient descent)에서 유도된 방법이다. 경사 하강법은 가중치에 대한 손실 함수를 미분하고 그 미분값의 방향과 크기를 사용해 가중치를 보상하는 방법이다.

손실 함수(loss function) : 가중치에 따라 오차가 얼마나 커지는지 작아지는지를 평가한다. 

분류 ANN은 손실함수로 교차 엔트로피(cross entropy)함수를 주로 사용한다. 교차 엔트로피 함수를 적용하려면 출력 노드의 결과를 확률 값으로 바꿔야 한다. 확률 값은 출력 노드 값을 소프트맥스 연산으로 구한다.

#### [ 회귀 ANN ] ####

회귀 ANN이란?

- 입력값으로부터 출력값을 직접 예측하는 방법이다.

- 실제 데이터가 분포해 있다고 할 때 이 데이터의 규칙을 잘 표현하는 함수를 찾는 것이 회귀이다.

- 예를 들어 다중 회귀를 이용하면 집과 관련된 정보를 활용해서 집값을 예측할 수 있다. 

- 신경망 학습은 많은 집 정보를 이용하여 수행하게 된다. 

- 신경망 학습이 완료되면 집에 대한 정보와 시세 간의 관계가 성립된다. 즉, 임의의 집정보를 넣으면 시세를 예측할 수 있다. 물론 학습에 사용하지 않은 집에 대한 정보로도 시세를 예측할 수 있다.

- ANN학습은 분류 ANN에서와 같이 **오차역전파 방법을 사용한다.**

- 회귀 ANN을 오차역전파 방법으로 학습시키려면 주로 평균제곱오차(mean-square error)를 손실함수로 사용한다.

*오차 역전파를 활용해 학습하는 최적화 방법으로 확률적 경사 하강법을 많이 사용해왔다. 최근에는 더 발전된 방법으로 Adam, Adagrad, RMSprop 등과 같은 방법을 사용한다.*

*다양한 최적화 방법 중에 주어진 데이터에 맞는 하나를 선택해야 한다.*

### 2.1.4 ANN 구현 방법 및 단계 ### 

인공지능을 케라스로 구현하는 방법은 크게 **함수형 구현**과 **객체지향형 구현**이 있다. 

  - 함수형 구현 : ANN모델을 직접 설계하는 인공지능 전문가에게 적합
  - 객체 지향방식 구현: 전문가가 만들어놓은 ANN모델을 사용하는 사용자에게 적합

ANN모델링은 분산 방식, 연쇄 방식 또는 둘의 혼합 방식으로 구현할 수 있다. 

분산 방식은 구조가 복잡한 경웨 적합하며 연쇄 방식은 하나의 순서로 구성된 간단한 신경망의 구현에 적합하다.

< 구현 순서 >

1. 인공지능 구현용 패키지 불러오기
2. 인공지능에 필요한 파라미터 설정
3. 인공지능 모델 구현
4. 학습과 성능 평가용 데이터 불러오기
5. 인공지능 학습 및 성능평가
6. 인공지능 학습 결과 분석

## 2.2 필기체를 구분하는 분류 ANN 구현 ##

케라스로 분류 ANN을 구현하면서 기본적인 인공지능 구현 방법을 익혀보자.

또한 학습이나 평가에 사용할 데이터를 인공지능 알고리즘에 적용하기 전에 어떻게 전처리하는지도 알아보자.

분류 ANN 구현도 앞에서 설명한 인공지능 구현 6단계를 따른다.

1. 분류 ANN 구현용 패키지 불러오기
2. 분류 ANN에 필요한 파라미터 설정
3. 분류 ANN 모델 구현
4. 학습과 성능 평가용 데이터 불러오기
5. 분류 ANN 학습 및 검증
6. 분류 ANN 학습 결과 분석

### 2.2.1 분류 ANN을 위한 인공지능 모델 구현 ### 

1. 케라스 패키지로 2가지 모듈을 불러온다.

        from keras import layers, models
        
    - layers : 각 계층을 만드는 모듈
    - models : 각 layer들을 연결하여 신경망 모델을 만든 후, 컴파일하고 , 학습시키는 역할
    - 객체 지향 방식을 지원하는 케라스는 **models.Model 객체에서 complie() , fit(), predict(), evaluate() 등 딥러닝 처리 함수 대부분을 제공**해 편리하게 사용할 수 있다.

2. 분류 ANN에 필요한 파라미터 설정한다.

필요한 파라미터는 Nin(입력 계층의 노드 수), Nh(은닉 계층의 노드 수), number_of_class(출력값이 가질 클래스 수), Nout(출력 노드 수)이다.

실제 이 값의 정의는 main()함수 안에서 진행한다( 꼭 전역 변수로 지정할 필요 없다면 파라미터들을 시작 함수인 main()에 넣어준다 ).


3. 모델링

분류 ANN모델은 인공지능 기술에서 가장 기본이 되는 구조이다.

연쇄 방식은 복잡도가 높은 모델에 적용하기에는 한계가 있기 때문에 분산 방식까지 알아두는 것이 좋다.

또한 모델을 구현하는 방식도 함수형과 객체지향형 방법을 모두 다룬다.

< 고려하는 모델 구현 방식 >
   
  1) 분산 방식 모델링을 포함하는 함수형 구현
  2) 연쇄 방식 모델링을 포함하는 함수형 구현
  3) 분산 방식 모델링을 포함하는 객체지향형 구현
  4) 분산 방식 모델링을 포함하는 객체지향형 구현

**[ 분산 방식 모델링을 포함하는 함수형 구현 ]**

- 입력계층 정의
  
       x = layers.Input(shape(Nin,))  # 원소 Nin개를 가지는 입력 신호 벡터
       
- 은닉 계층 정의

       h = layers.Activation('relu')(layers.Dense(Nh)(x))
       
    - 은닉 계층은 layers.Dense()로 지정한다. 노드가 Nh개인 경우에 은닉 계층을 layers.Dense(Nh)(x)로 지정한다. 참고로 layers.Dense(Nh)는 layers.Dense 객체의 인스턴스이다.

    - 객체를 함수처럼 사용할 수 있기 때문에 ()를 사용해 호출이 가능한 것이다.

    - 활성화 함수는 layers.Activation('relu')로 지정한다. 

    - **입력 벡터인 x를 완전히 연결된 은닉 계층의 노드들로 모두 보내고 은닉 계층의 각 노드들은 ReLU로 활성화 처리한 뒤에 다음 계층으로 내보낸다.**

- 출력 계층

      y = layers.Activation('softmax')(layers.Dense(Nout)(h))
      
    - 다중 클래스 분류를 ANN으로 구현하고 있으므로 출력 노드 수는 클래스 수 (Nout)으로 지정한다. 

    - 이 때 **출력 노드에 입력되는 정보는 은닉 노드의 출력값이다.**

- 인공지능 모델 만들기
  
     - 앞서 설명한 계층들을 합쳐 인공지능 모델을 만든다.
     
     - 케라스는 컴파일을 수행하여 타깃 플래폼에 맞게 딥러닝 코드를 구성한다.

     - 컴파일(모델 파라미터를 통해 모델 구조를 생성하는 과정) 과정
      
            model. compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
            
          loss : 손실함수 / 
          optimizer : 최적화 함수 / 
          metrics : 학습이나 예측이 진행될 때 성능 검증을 위해 손실 뿐 아니라 정확도도 측정하라는 의미
      
      
**[ 연쇄 방식 모델링을 포함하는 함수형 구현 ]**      

분산 방식과 다르게 모델을 먼저 설정한다.

- 모델 설정
        
          model = models.Sequential()
          
  - 연쇄 방식은 모델 구조를 정의하기 전에 Sequential()함수로 모델을 초기화 해야한다.

- 모델의 구조 설정

        model.add(layers.Dense(Nh, activation = 'relu', input_shape = (Nin,))
        model.add(layers.Dense(Nout, activation = 'softmax')
        
  - 첫 번째 add() 단계에서 입력 계층과 은닉 계층의 형태가 동시에 정해진다. 

  - **입력노드 Nin개는 완전 연결 계층 Nh개로 구성된 은닉 계층으로 보내지며 이 은닉 계층 노드들은 ReLU활성화 함수로 사용한다.**

  - **은닉 계층의 출력은 출력이 Nout개인 출력노드로 보내진다. 출력 노드들의 활성화 함수는 소프트맥스 연산으로 지정했다.**
      
  - 이처럼 연쇄 방식은 추가되는 계층을 기술할 때 간편하게 기술할 수 있다는 장점이 있다(add()를 이용해 연속되는 계층을 계속 더해주면 된다).

  - 복잡한 인공신경망을 기술하는 부분은 연쇄 모델링만으로 구현이 힘든 경우도 존재 => **분산 방식 모델링**을 사용해야한다.
      
**[ 분산 방식 모델링을 포함하는 객체지향형 구현 ]**        

ANN 코드의 재사용성을 높이기 위해 객체지향 방식으로 구현할 수도 있다.

먼저 클래스를 만들고 models.Model로부터 특성을 상속해온다. models.Model은 신경망에서 사용하는 학습, 예측, 평가와 같은 다양한 함수를 제공한다.

- 클래스의 초기화 함수를 정의

        class ANN(models.Model):
          def __init__(self,Nin,Nh,Nout):
          
  - 초기화 함수는 입력 계층, 은닉 계층, 출력 계층의 노드 수를 각각 Nin,Nh,Nout으로 받는다. 

- 신경망 모델에 사용할 계층을 정의

        hidden = layers.Dense(Nh)
        
  - 은닉 계층이 하나이므로 은닉 계층 출력 변수로 hidden하나만 사용했다.

  - 은닉 계층이 만약 셋이라면 반복문을 사용해서 생성할 수 있다.

  - 이 때는 각 계층마다 노드 수가 Nh_1 = [5,10,5]라고 한다. 은닉 계층들을 hidden_1 = map(layers.Dense,Nh_1)과 같이 반복문을 사용해서 만들 수 있다.

  - for문을 사용해서 hidden_1 = [layers.Dense(n) for n in Nh_1]과 같이 만들 수 있다.

  - 단일 문장이 아니라 여러 문장으로 구성한다면 다음과 같이 구성할 수 있다.

        hidden_1 = []
        for n in Nh_1
          hidden_1.append(layers.Dense(n))
 
- 이제 노드 수가 Nout개인 출력 계층 정의

        output = layers.Dense(Nout)
  
- activation함수를 정의

        relu = layers.Activation('relu')
        softmax = layers.Activation('softmax')
        
- 상속 받은 부모 클래스의 초기화를 진행
  
        super().__init__(x,y)
        
  - 여기서 부모 클래스가 models.Model이다. 적어주지 않으면 자동으로 선정된다.

- 모델 사용하기 위해 인스턴스 생성

      model = ANN(Nin,Nh,Nout)
      
**케라스를 이용하면 이렇게 만들어진 모델을 불러와서 사용하면 되므로 복잡한 인공지능 수식을 일일이 파악해야하는 수고가 줄어든다. 따라서 클래스를 사용하는 객체지향형 구현 방식을 이용하면 케라스를 더욱 쉽게 사용할 수 있다.**
      
      
**[ 연쇄 방식 모델링을 포함하는 객체지향형 구현 ]**        
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
