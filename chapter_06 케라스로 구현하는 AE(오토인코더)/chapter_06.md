# Chapter 06 #

📍 오토인코더란?

- 비지도학습 인공지능이다. 지금까지 다룬 모델들은 목표값으로 학습하는 지도학습 인공지능이었다.

- 지도학습과 다르게 비지도학습은 입력 데이터를 가공하여 목표값을 출력하는 방식이 아니라 레이블 정보가 없는 데이터의 특성을 분석하거나 추출한다.

- 비지도학습의 대표적인 방식인 오토인코더(AE)의 목적은 입력 데이터의 특징점을 효율적으로 찾는 것이다.

- 다차원 입력 데이터를 저자원 부호로 바꾸고 다시 저차원 부호를 처음 입력한 다차원 데이터로 바꾸면서 특징점들을 찾아낸다.

- AE의 출력 데이터는 입력한 데이터에 비해 정보의 차원이 줄기 때문에 잡음을 제거하는 용도로도 사용할 수 있다.

## 6.1 AE의 원리 ##

**오토인코더**는 입력한 데이터를 부호화한 후 복호화하는 신경망이다.

그 결과 입력 데이터의 특징점을 추출한다. 

주로 활용되는 곳은 데이터 압축, 저차원화를 통한 데이터 관계 관찰, 배경 잡음 억제 등입니다.

AE는 주성분 분석으로 처리하는 일차원 데이터 처리 방식을 딥러닝 방식으로 확장한 것이다.

AE는 신경망으로 특징점을 추출하기 때문에 데이터 구성이 복잡하거나 데이터가 대량인 경우에 주성분 분석 방법보다 더 효과적이다.

AE의 동작은 **부호화 과정**과 **복호화 과정**으로 이루어진다.

  - 부호화 과정 

    1. 입력 계층에서 들어온 다차원 데이터는 차원을 줄이는 은닉 계층으로 들어간다.
    2. 은닉 계층의 출력이 곧 부호화 결과이다.

  - 복호화 과정

    1. 은닉 계층에서 출력한 부호화 결과는 출력 계층으로 들어간다. 이때 출력 계층의 노드 수는 은닉 계층의 노드 수보다 많다. 즉, 더 높은 차원의 데이터로 되돌아간다.
    2. 출력 계층은 입력 계층과 노드 수가 동일하다.

▶ 이것과 같이 AE는 데이터의 차원을 줄였다가 늘려 부호화와 복호화가 연속적으로 일어나게 된다. AE의 부호화 및 복호화 과정에 사용되는 은닉 계층 수는 여럿일 수 있다.

## 6.2 완전 연결 계층을 이용한 AE 구현 ##

MNIST(필기체 숫자)를 이용하여 AE를 구현해보자. 

AE를 구성하는 계층이 완전 연결 계층이라고 가정하자. 

이번 절의 핵심은 **AE가 필기체 숫자를 차원이 작은 데이터로 부호화한 뒤 원래 이미지와 유사하게 다시 복호화할 수 있느냐이다.**

복구가 잘 된다면 필기체 숫자는 차원이 줄어든 부호화 데이터로 변경이 가능하고 이후는 이 줄어든 부호로 정보 전달 또는 데이터 분류 등의 처리가 가능해진다.

완전 연결 계층 AE는 다음과 같은 순서로 구현한다.

1) 완전 연결 계층 AE 모델링
2) 데이터 준비
3) 완전 연결 계층 AE 학습
4) 학습 효과 분석
5) 완전 연결 계층 AE 동작 확인

### 6.2.1 완전 연결 계층 AE 모델링 ###

1️⃣ AE를 위한 딥러닝 모델을 만든다. 우선 모델링에 필요한 케라스 서브 패키지들을 불러온다.

    from keras import layers,models
    
- 이제 객체를 구성하여 AE 모델링을 수행한다.

      class AE(models.Model):
        def __init__(self,x_nodes, z_dim):
          x_shape = (x_nodes,)
          
     - 객체의 초깃값으로 입력 노드 수(x_nodes), 은닉 노드 수(z_dim)를 지정했다.
     - 입력 계층의 구조를 나타내는 x_shape은 입력 노드 수(x_node)로 구성된 튜플로 정의했다.
     
     ❗ 파이썬 배열은 3가지이다. 가장 간단한 것이 **튜플**이다. 튜플은 (a,b,c)와 같이 괄호를 이용해 구성한다. 나머지 둘은 대괄호로 구성하는 **리스트(list)** 와 중괄호로 구성하는 **딕셔너리(dictionary)** 가 있다.

- AE의 입력 계층, 은닉 계층, 출력 계층을 정의할 단계이다.

      x = layers.Input(shape = x_shape)  # 입력 계층
      z = layers.Dense(z_dim, activation='relu')   # 은닉 계층
      y = layers.Dense(x_nodes, activation='sigmoid')   # 출력 계층

    - 입력 계층과 출력 계층의 노드 수를 같게 구성하였다. 
    
    - 중간에 들어 있는 은닉 계층은 z_dim값에 따라 노드 수가 정해진다.
    
    - 은닉 계층의 활성화 함수는 ReLU로 설정했고 출력 계층의 활성화 함수는 시그모이드로 지정했다(시그모이드 지정 이유 : 입력 이미지의 특성을 반영하기 위해서).
    
    - 그리고 입력으로 사용할 MNIST 이미지는 완전 흰색 또는 완전 검은색에 가까운 색으로 구성되어 있기 때문이다. 만약 픽셀들이 흰색과 검은색 사이의 회색으로 골고루 분포하는 경우에는 출력 계층의 활성화 함수로 선형 함수가 더 적합하다.

- AE의 구조를 확정하고 컴파일한다.

      super().__init__(x,y)
      self.compile(optimizer = 'adadelta', loss = 'binary_crossentropy'

  - 손실 함수를 binary_crossentropy로 설정했다. 교차 엔트로피는 분류 문제에 주로 사용하지만 이 예제에서는 AE용으로도 사용했다.

- AE모델링과 직접 상관은 없지만 추후에 AE 동작을 확인하는 데 필요한 부분을 구현한다.

✔ AE를 구성하는 특정 계층의 출력 값을 뽑아내거나 특정 계층에 새로운 입력값을 넣어서 결과를 보는 방법을 다룬다. 이를 구현하려면 객체의 초기화 함수에서 필요한 계층들과 몇몇 초기 파라미터를 저장해둘 필요가 있다.

    self.x = x
    self.z = z
    self.z_dim = z_dim
    
   - 입력 계층, 은닉 계층, 은닉 계층의 노드 수를 객체 멤버 변수로 저장했다.

- AE는 복호화와 부호화가 자동으로 수행되는 모델이다. 부호화가 어떻게 진행되는지 알고싶을 때는 AE중간에 있는 은닉 계층이 결과를 출력으로 하는 별도의 부호화 모델을 설정해 신경망 외부에서 부호화한 결과를 확인할 수 있다.

      def Encoder(self):
        return models.Model(self.x,self.z)

- 외부에서 새로운 부호화 데이터를 넣어 복호화하는 결과를 얻는 방법도 제공한다. 이를 위해서 모니터링을 제공할 별도 복호화 모델을 만든다. 이 복호화 모델은 새롭게 입력을 정의하고 전체 AE모델에서 복호화 계층을 가져와 만든다.

      def Decoder(self):
        z_shape = (self.z_dim,)
        z = layers.Input(shape= z_shape)
        y_layer = self.layers[-1]
        y = y_layer(z)
        return models.Model(z,y)
  
  - 외부에 새롭게 들어오는 입력에 대응하므로 새로운 입력을 Input()으로 만들었다.

  - 그리고 다음 은닉 계층은 기존에 사용하던 은닉 곛ㅇ을 다시 사용하기 때문에 기존에 만든 계층 중 하나를 변수 self에서 가져왔다.

  - self.layers[-1]은 제일 마지막 부분 즉 AE 자신의 출력 계층이라는 의미이다.

✅ 지금까지 **AE 고유 모델과 부호화와 복호화를 각각 수행하는 추가 모델을 만들었다.** 고유 모델을 만들 때 공통 파라미터를 자기 멤버 변수로 지정해두어 손쉽게 추가 모델을 구현할 수 있었다.









